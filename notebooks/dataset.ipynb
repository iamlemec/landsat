{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import mectools.data as dt\n",
    "import sklearn.model_selection as sk\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import tools\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plotter(backend='agg')\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'asie'\n",
    "year = 2003\n",
    "channel = ['density']\n",
    "landsat = 'mincloud2002'\n",
    "size = 1024\n",
    "ivar = 'id'\n",
    "yvar = 'log_tfp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix = 256\n",
    "val_frac = 0.2\n",
    "batch_size = 128\n",
    "buffer = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source == 'asie':\n",
    "    firms = data.load_asie_firms(year, landsat)\n",
    "elif source == 'census':\n",
    "    firms = data.load_census_firms(year, landsat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random geographic split\n",
    "# state = np.random.RandomState(21921351)\n",
    "# df_train, df_valid = tools.categ_split(firms, 'city', val_frac, state=state)\n",
    "# print(len(df_valid)/(len(firms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure random split\n",
    "df_train, df_valid = sk.train_test_split(firms, test_size=val_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_path = f'../data/tiles_fast/{source}{year}'\n",
    "def parse_function(fid, out):\n",
    "    image = tf.concat([data.load_tile(fid, f'{tile_path}/{ch}/{size}px') for ch in channel], -1)\n",
    "    return (fid, image), out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df):\n",
    "    fids = tf.constant(df[ivar])\n",
    "    labels = tf.reshape(tf.cast(tf.constant(df[yvar]), tf.float32), (-1, 1))\n",
    "    data = tf.data.Dataset.from_tensor_slices((fids, labels))\n",
    "    data = data.map(parse_function)\n",
    "    data = data.shuffle(buffer_size=buffer)\n",
    "    data = data.batch(batch_size)\n",
    "    data = data.repeat()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = make_dataset(df_train), make_dataset(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.gen_dual_medium(pix, len(channel))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train keras model\n",
    "history = model.fit(train, validation_data=valid, epochs=5, steps_per_epoch=2000, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x00, y00 = next(iter(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, yh_test = tools.predict_data(model, valid, 100)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(11, 5))\n",
    "tools.eval_model(y_test, yh_test, N=10, axs=(ax0, ax1), qmin=0.02, qmax=0.98)\n",
    "if save: fig.savefig('../docs/images/asie_tfp_medium_valid.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, yh_test = tools.predict_data(model, train, 100)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(11, 5))\n",
    "tools.eval_model(y_test, yh_test, qmin=0.02, qmax=0.98, N=10, axs=(ax0, ax1))\n",
    "if save: fig.savefig('../docs/images/asie_tfp_medium_train.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_city = smf.ols(f'log_tfp ~ C(city)', data=firms).fit()\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(11, 5))\n",
    "tools.eval_model(firms['log_tfp'], ret_city.predict(), qmin=0.02, qmax=0.98, N=10, axs=(ax0, ax1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_radial = models.gen_radial_pool(pix, len(channel), 3)\n",
    "model_radial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_radial = model_radial.fit(\n",
    "    train, validation_data=valid, epochs=5, steps_per_epoch=1000, validation_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_radial.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, yh_test = tools.predict_data(model_radial, valid, 100)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(11, 5))\n",
    "tools.eval_model(y_test, yh_test, N=10, axs=(ax0, ax1), qmin=0.02, qmax=0.98)\n",
    "fig.savefig('../docs/images/asie_tfp_radial_valid.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, yh_test = tools.predict_data(model_radial, train, 100)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(11, 5))\n",
    "tools.eval_model(y_test, yh_test, qmin=0.02, qmax=0.98, N=10, axs=(ax0, ax1))\n",
    "fig.savefig('../docs/images/asie_tfp_radial_train.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}