{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.nonparametric.kde import kdensityfft\n",
    "import sklearn.model_selection as sk\n",
    "import mectools.data as dt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plotter(backend='Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "seed = 2384923\n",
    "samp = 0.01\n",
    "BATCH_SIZE = 32\n",
    "imsize = 256\n",
    "pixel = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random init\n",
    "state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def load_path(tag, base='../tiles/density', size=1024, ext='jpg'):\n",
    "    tag = f'{tag:07d}'\n",
    "    sub = tag[:4]\n",
    "    return f'{base}/{size}px/{sub}/{tag}.{ext}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "def eval_model(y, yhat, ymin=-2, ymax=2, nbins=10, axs=None):\n",
    "    if axs is None:\n",
    "        _, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "    else:\n",
    "        ax0, ax1 = axs\n",
    "\n",
    "    res = pd.DataFrame({'y': y, 'yhat': yhat}).astype(np.float)\n",
    "    res['err'] = res['yhat'] - res['y']\n",
    "    res1 = res.query(f'y > {ymin} and y < {ymax} and yhat > {ymin} and yhat < {ymax}')\n",
    "    ax0.hexbin(res1['y'], res1['yhat'], cmap=mpl.cm.Blues, gridsize=20);\n",
    "    \n",
    "    bins = np.linspace(ymin, ymax, nbins)\n",
    "    res['ybin'] = np.digitize(res['y'], bins)\n",
    "    res['ybin'] = np.minimum(nbins-1, res['ybin'])\n",
    "    bmean = res.groupby('ybin')['yhat'].mean()\n",
    "    bmean = bmean.reindex(np.arange(nbins))\n",
    "    bmean.index = bins\n",
    "    bmean.plot(ax=ax1);\n",
    "    \n",
    "    ax0.set_xlabel('True Productivity')\n",
    "    ax0.set_ylabel('Predicted Productivity')\n",
    "    ax0.set_title('Joint Distribution')\n",
    "    ax1.set_xlabel('True Productivity')\n",
    "    # ax1.set_ylabel('Predicted Productivity')\n",
    "    ax1.set_title(f'Binned Results ({nbins})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in firm and location data\n",
    "firms = pd.read_csv('../firms/census_2004_geocode.csv', usecols=['id', 'industry', 'income', 'total_assets', 'employees'])\n",
    "targ = pd.read_csv('../targets/census_firms_2004.csv', usecols=['id', 'lat_wgs84', 'lon_wgs84'])\n",
    "firms = pd.merge(firms, targ, on='id', how='left').dropna()\n",
    "\n",
    "# downsample for now\n",
    "firms = firms.sample(frac=samp, random_state=seed)\n",
    "\n",
    "# resolve image paths\n",
    "base = '../tiles/landsat'\n",
    "firms['file_density_256'] = firms['id'].apply(lambda t: load_path(t, base='../tiles/density', size=256))\n",
    "firms['file_density_1024'] = firms['id'].apply(lambda t: load_path(t, base='../tiles/landsat', size=1024))\n",
    "firms['fexist_density_256'] = firms['file_density_256'].apply(os.path.exists)\n",
    "firms['fexist_density_1024'] = firms['file_density_1024'].apply(os.path.exists)\n",
    "print(len(firms))\n",
    "firms = firms[firms['fexist_density_256']&firms['fexist_density_1024']]\n",
    "print(len(firms))\n",
    "\n",
    "# calculate outcome stats\n",
    "firms['prod'] = firms['income']/firms['employees']\n",
    "firms['lprod'] = dt.log(firms['prod'])\n",
    "firms = firms.dropna(subset=['lprod'])\n",
    "\n",
    "# calculate residual performance\n",
    "reg_ind = smf.ols('lprod ~ 0 + C(industry)', data=firms).fit()\n",
    "firms['lprod_resid'] = reg_ind.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in image features\n",
    "density_256 = np.stack([np.array(PIL.Image.open(fn)) for fn in firms['file_density_256']])\n",
    "density_1024 = np.stack([np.array(PIL.Image.open(fn)) for fn in firms['file_density_1024']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.stack([density_256, density_1024], axis=-1).astype(np.float32)/255 # single channel image\n",
    "# features = np.stack([density_1024], axis=-1).astype(np.float32)/255 # single channel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct outcome variable\n",
    "labels = firms['lprod'].values\n",
    "labels_resid = firms['lprod_resid'].values\n",
    "labels = labels[:,None].astype(np.float32)\n",
    "labels_resid = labels_resid[:,None].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/test split\n",
    "X_train, X_valid, y_train, y_valid, yr_train, yr_valid = sk.train_test_split(features, labels, labels_resid, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR like model (1024px)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=8),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=4),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR like model (1024px) - multichannel\n",
    "model = keras.Sequential([\n",
    "    keras.layers.DepthwiseConv2D(depth_multiplier=4, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=8),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.DepthwiseConv2D(depth_multiplier=4, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=4),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR like model (256px)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=8),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=4, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=4),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=32, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=16),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train keras model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid = model.predict(X_valid)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "eval_model(y_valid[:,0], yhat_valid[:,0], ymin=2, ymax=6, axs=(ax0, ax1))\n",
    "if save: fig.savefig('../docs/images/cnn_results_valid.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model.predict(X_train)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "eval_model(y_train[:,0], yhat_train[:,0], ymin=2, ymax=6, axs=(ax0, ax1))\n",
    "if save: fig.savefig('../docs/images/cnn_results_train.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean = keras.Sequential([\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model_mean.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model_mean.fit(X_train, y_train, epochs=25, validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid = model_mean.predict(X_valid)\n",
    "eval_model(y_valid[:,0], yhat_valid[:,0], ymin=2, ymax=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model_mean.predict(X_train)\n",
    "eval_model(y_train[:,0], yhat_train[:,0], ymin=2, ymax=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadialPooling2D(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        size0 = self.add_weight(name='size0', shape=(1,), initializer='uniform', trainable=True)\n",
    "        size = 128*keras.activations.sigmoid(size0)\n",
    "        _, span_x, span_y, _ = input_shape\n",
    "        zero_x, zero_y = int(span_x//2), int(span_y//2)\n",
    "        vals_x, vals_y = tf.cast(tf.range(span_x), tf.float32), tf.cast(tf.range(span_y), dtype=tf.float32)\n",
    "        grid_x, grid_y = tf.meshgrid(vals_x, vals_y)\n",
    "        radius = tf.sqrt((grid_x-zero_x)**2+(grid_y-zero_y)**2)\n",
    "        self.mask = keras.activations.sigmoid(-(radius-size)/10)[None,:,:,None]\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.reshape(tf.reduce_mean(tf.multiply(x, self.mask)), (-1, 1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "inputs = keras.layers.Input(shape=(imsize, imsize, 1))\n",
    "pool = keras.layers.Concatenate()([RadialPooling2D()(inputs) for _ in range(5)])\n",
    "outputs = keras.layers.Dense(1)(pool)\n",
    "model_radial = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model_radial.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model_radial.fit(X_train, y_train, epochs=25, validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid = model_radial.predict(X_valid)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "eval_model(y_valid[:,0], yhat_valid[:,0], ymin=2, ymax=6, axs=(ax0, ax1))\n",
    "fig.savefig('../slides/images/radial_results.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model_radial.predict(X_train)\n",
    "eval_model(y_train[:,0], yhat_train[:,0], ymin=2, ymax=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgrid = np.arange(imsize)\n",
    "grid_x, grid_y = np.meshgrid(imgrid, imgrid)\n",
    "zero_x, zero_y = imsize // 2, imsize // 2\n",
    "zdist = np.sqrt((grid_x-zero_x)**2+(grid_y-zero_y)**2)\n",
    "def radial_density(dense, rad0, rad1):\n",
    "    mask = (zdist >= rad0) & (zdist <= rad1)\n",
    "    return (mask[None,:,:]*dense).mean(axis=(1, 2))\n",
    "for rad0, rad1 in ((0, 32), (32, 64), (64, 128)):\n",
    "    firms[f'dense_{rad0}_{rad1}'] = radial_density(features[:,:,:,0], rad0, rad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_radial = smf.ols('lprod ~ 1 + dense_0_32 + dense_32_64 + dense_64_128', data=firms).fit()\n",
    "reg_radial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_radial = reg_radial.predict()\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "eval_model(firms['lprod'].values, yhat_radial, ymin=2, ymax=6, axs=(ax0, ax1))\n",
    "fig.savefig('../slides/images/ols_results.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "firms1 = dt.winsorize(firms[['lprod', 'lprod_resid']], level=0.001)\n",
    "jp = sns.jointplot('lprod', 'lprod_resid', data=firms1, kind='hex');\n",
    "jp.set_axis_labels('Log Productivity', 'Residual Log Productivity');\n",
    "jp.savefig('../slides/images/residual_distribution.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, yr_train, epochs=25, validation_data=[X_valid, yr_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrhat_valid = model.predict(X_valid)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "eval_model(yr_valid[:,0], yrhat_valid[:,0], ymin=-1.5, ymax=1.5, axs=(ax0, ax1))\n",
    "fig.savefig('../slides/images/resid_results_valid.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrhat_train = model.predict(X_train)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "eval_model(yr_train[:,0], yrhat_train[:,0], ymin=-1.5, ymax=1.5, axs=(ax0, ax1))\n",
    "fig.savefig('../slides/images/resid_results_train.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 300\n",
    "eps = 1e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda x: x/(x+norm)\n",
    "quantize = lambda x: (256*(x-eps)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_empty = np.zeros((1, imsize, imsize, 1))\n",
    "model.predict(X_empty)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_density(dat, sigma=2):\n",
    "    count, lon_bins, lat_bins = np.histogram2d(dat[:,0], dat[:,1], bins=imsize, range=((0, 1), (0, 1)))\n",
    "    dens = count/(4*pixel/1e3)**2 # firms per square kilometer\n",
    "    dens = gaussian_filter(dens, sigma=sigma)\n",
    "    dimg = quantize(normalize(dens))\n",
    "    return dimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsim = len(features)\n",
    "features1 = features[:nsim,:,:,0]\n",
    "dense = np.stack([gen_density(0.5+0.1*np.random.randn(50, 2)) for _ in range(nsim)])\n",
    "augment = np.stack([f+d for f, d in zip(features1, dense)])\n",
    "aug_pred = model.predict(augment[:,:,:,None])[:,0].astype(np.float)\n",
    "bas_pred = model.predict(features1[:,:,:,None])[:,0].astype(np.float)\n",
    "dif_pred = aug_pred - bas_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dif_pred.mean())\n",
    "print((dif_pred>0).mean())\n",
    "plt.hist(dif_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_pred1 = dif_pred[(dif_pred<3.5)&(dif_pred>-2)]\n",
    "kde_vals, kde_grid, kde_bw = kdensityfft(dif_pred1)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.plot(kde_grid, kde_vals)\n",
    "ax.set_xlabel('Change in Log Productivity')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Adding 50 Additional Firms')\n",
    "fig.savefig('../slides/images/impulse_response.png', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}